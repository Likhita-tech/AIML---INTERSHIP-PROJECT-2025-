import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load your dataset
df = pd.read_csv("diamonds.csv")  # Make sure the file exists

# Encode categorical columns
label_cols = ['cut', 'color', 'clarity']
le = LabelEncoder()
for col in label_cols:
    df[col] = le.fit_transform(df[col])

# Features and Target
df['size'] = df['x'] * df['y'] * df['z']
X = df[['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'size']]
y = df['price']
print(df.columns)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model: Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Prediction
y_pred = model.predict(X_test)

# Evaluation
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

# Visualization
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.title("Actual vs Predicted Diamond Price")
plt.show()
